{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ee2c734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (output): Linear(in_features=3, out_features=2, bias=True)\n",
      ")\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "Model 1 reached 100% accuracy at epoch 16\n",
      "Model Accuracy: 1.0%\n",
      "Model weights:\n",
      "hidden.weight tensor([[-0.0754,  0.0399],\n",
      "        [ 0.7062, -0.5095],\n",
      "        [ 0.6274,  0.3649]])\n",
      "hidden.bias tensor([ 0.1803, -0.6232, -0.1830])\n",
      "output.weight tensor([[ 0.2363,  0.6075, -0.0527],\n",
      "        [ 0.6147,  0.0086, -0.1414]])\n",
      "output.bias tensor([-0.0903,  0.2300])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model1 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 3)),  # first hidden layer with 3 neurons\n",
    "    ('sigmoid', nn.Sigmoid()),    # sigmoid activation function\n",
    "    ('output', nn.Linear(3, 2)),  # output layer with 2 neurons\n",
    "    ('sigmoid', nn.Sigmoid())     # sigmoid activation function\n",
    "]))\n",
    "print(model1)\n",
    "\n",
    "data_in1 = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float)\n",
    "print(data_in1)\n",
    "\n",
    "data_target1 = torch.tensor([[0, 0], [0, 1], [0, 1], [1, 0]], dtype=torch.float)\n",
    "print(data_target1)\n",
    "\n",
    "criterion1 = nn.MSELoss()\n",
    "optimizer1 = torch.optim.SGD(model1.parameters(), lr=0.1)\n",
    "\n",
    "# train the model\n",
    "losses1 = []\n",
    "for epoch in range(10000):\n",
    "    # reset the gradients to zero before each forward and backward pass\n",
    "    optimizer1.zero_grad()  \n",
    "    # forward pass\n",
    "    outputs1 = model1(data_in1)\n",
    "    # calculate loss\n",
    "    loss1 = criterion1(outputs1, data_target1)\n",
    "    # backward pass\n",
    "    loss1.backward()          \n",
    "    # update weights\n",
    "    optimizer1.step()         \n",
    "    losses1.append(loss1.item())\n",
    "    \n",
    "    # accuracy\n",
    "    predicted_classes1 = (outputs1.round() == data_target1)\n",
    "    accuracy1 = predicted_classes1.sum().item() / len(data_target1)\n",
    "    if accuracy1 == 1:\n",
    "        print(f\"Model 1 reached 100% accuracy at epoch {epoch+1}\")\n",
    "        break\n",
    "        \n",
    "        \n",
    "# visualize the resuts\n",
    "predicted = torch.round(outputs1)\n",
    "correct = (predicted == data_target1).sum()\n",
    "total = data_target1.size(0)\n",
    "accuracy = correct / total\n",
    "print(f'Model Accuracy: {accuracy}%')  \n",
    "\n",
    "    \n",
    "# print model wights\n",
    "print(f\"Model weights:\")\n",
    "for name, param in model1.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0e6684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
