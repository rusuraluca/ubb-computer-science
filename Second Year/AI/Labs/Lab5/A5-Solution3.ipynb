{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45cc7a0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (ReLU): ReLU()\n",
      "  (output): Linear(in_features=3, out_features=2, bias=True)\n",
      "  (tanh): Tanh()\n",
      ")\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "Model 1 reached 100% accuracy at epoch 2\n",
      "tensor([[ 0.4958, -0.1303],\n",
      "        [ 0.6364, -0.3876],\n",
      "        [ 0.5722, -0.1275],\n",
      "        [ 0.7356, -0.4573]], grad_fn=<TanhBackward0>)\n",
      "Model Accuracy: 1.0%\n",
      "Model weights:\n",
      "hidden.weight tensor([[ 0.0274,  0.0272],\n",
      "        [-0.3173,  0.1806],\n",
      "        [ 0.3455,  0.5465]])\n",
      "hidden.bias tensor([ 0.4441,  0.3299, -0.2096])\n",
      "output.weight tensor([[ 0.3619, -0.0030,  0.4864],\n",
      "        [ 0.1176, -0.3293, -0.5019]])\n",
      "output.bias tensor([0.3492, 0.0247])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model1 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 3)),  # first hidden layer with 3 neurons\n",
    "    ('ReLU', nn.ReLU()),          # relu activation function\n",
    "    ('output', nn.Linear(3, 2)),  # output layer with 3 neurons\n",
    "    ('tanh', nn.Tanh())     # sigmoid activation function\n",
    "]))\n",
    "print(model1)\n",
    "\n",
    "data_in1 = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float)\n",
    "print(data_in1)\n",
    "\n",
    "data_target1 = torch.tensor([[0, 0], [0, 1], [0, 1], [1, 0]], dtype=torch.float)\n",
    "print(data_target1)\n",
    "\n",
    "criterion1 = nn.MSELoss()\n",
    "optimizer1 = torch.optim.SGD(model1.parameters(), lr=0.1)\n",
    "\n",
    "# train the model\n",
    "losses1 = []\n",
    "for epoch in range(1000):\n",
    "    # reset the gradients to zero before each forward and backward pass\n",
    "    optimizer1.zero_grad()    \n",
    "    outputs1 = model1(data_in1) # forward pass\n",
    "    loss1 = criterion1(outputs1, data_target1) # calculate loss\n",
    "    loss1.backward()          # backward pass\n",
    "    optimizer1.step()         # update weights\n",
    "    losses1.append(loss1.item())\n",
    "    predicted_classes1 = (outputs1.round() == data_target1)\n",
    "    accuracy1 = predicted_classes1.sum().item() / len(data_target1)\n",
    "    if accuracy1 == 1:\n",
    "        print(f\"Model 1 reached 100% accuracy at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "# visualize the resuts\n",
    "print(outputs1)\n",
    "predicted = torch.round(outputs1)\n",
    "correct = (predicted == data_target1).sum()\n",
    "total = data_target1.size(0)\n",
    "accuracy = correct / total\n",
    "print(f'Model Accuracy: {accuracy}%') \n",
    "\n",
    "# print model wights\n",
    "print(f\"Model weights:\")\n",
    "for name, param in model1.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384389b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
