{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0dd47bc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (output): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]])\n",
      "Model Accuracy: 0.0%\n",
      "Model weights:\n",
      "hidden.weight tensor([[-6.4407,  4.8643],\n",
      "        [-5.8451, -5.1272],\n",
      "        [-2.7106,  6.0360],\n",
      "        [-0.2127, -0.8915]])\n",
      "hidden.weight tensor(6.0360)\n",
      "hidden.bias tensor([-2.2685,  1.6049,  0.2056,  0.2154])\n",
      "hidden.bias tensor(1.6049)\n",
      "output.weight tensor([[ 8.6053, -7.1434, -7.8239,  1.6449]])\n",
      "output.weight tensor(8.6053)\n",
      "output.bias tensor([3.5040])\n",
      "output.bias tensor(3.5040)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 4)),  # first hidden layer with 4 neurons\n",
    "    ('sigmoid', nn.Sigmoid()),    # sigmoid activation function\n",
    "    ('output', nn.Linear(4, 1)),  # output layer with 1 neuron\n",
    "    ('sigmoid', nn.Sigmoid())     # sigmoid activation function\n",
    "]))\n",
    "print(model)\n",
    "\n",
    "data_in = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float)\n",
    "print(data_in)\n",
    "\n",
    "data_target = torch.tensor([[0], [1], [1], [0]], dtype=torch.float)\n",
    "print(data_target)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# train the model\n",
    "losses = []\n",
    "for epoch in range(10000):\n",
    "    # reset the gradients to zero before each forward and backward pass\n",
    "    optimizer.zero_grad()    \n",
    "    outputs = model(data_in) # forward pass\n",
    "    loss = criterion(outputs, data_target) # calculate loss\n",
    "    loss.backward()          # backward pass\n",
    "    optimizer.step()         # update weights\n",
    "    losses.append(loss.item())\n",
    "    predicted_classes = (outputs.round() == data_target)\n",
    "    accuracy = predicted_classes.sum().item() / len(data_target)\n",
    "    if accuracy == 1:\n",
    "        print(f\"Model reached 100% accuracy at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "# model accuracy\n",
    "predicted = torch.round(outputs)\n",
    "correct = (predicted == data_target).sum()\n",
    "total = data_target.size(0)\n",
    "accuracy = correct / total\n",
    "print(f'Model Accuracy: {accuracy}%')    \n",
    "\n",
    "# visualize the resuts\n",
    "\n",
    "# print the best one of the weights for each layer\n",
    "print(f\"Model weights:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "        print(name, torch.max(param.data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3f6465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72397d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
